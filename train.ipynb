{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c52b91c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c52b91c0",
        "outputId": "6ce130f1-e752-43a6-d813-e586a9dcb87f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting timm==0.5.4\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.5.4) (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.5.4) (9.4.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "! pip install torch numpy timm==0.5.4 tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "383c6887",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "383c6887",
        "outputId": "23654abe-22b3-446d-e397-40484ebee557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Vision-Transformer'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 33 (delta 13), reused 29 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (33/33), 31.23 KiB | 15.62 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tsungchiehchen/Vision-Transformer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "78da3d77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78da3d77",
        "outputId": "87859c5d-476e-4446-aa0d-d2aa32a82963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Vision-Transformer\n"
          ]
        }
      ],
      "source": [
        "%cd ./Vision-Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e7507140",
      "metadata": {
        "id": "e7507140"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import datetime\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from timm.models import create_model\n",
        "\n",
        "from engine import train_one_epoch, train_one_epoch_distillation, evaluate\n",
        "from utils import get_training_dataloader, get_test_dataloader\n",
        "import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "234c6ce8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "234c6ce8",
        "outputId": "1e75c1be-f6cc-4f72-e7de-3f0299bbfa93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: vit_base_patch16_224\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13411296.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "number of params: 86567656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "CHECKPOINT_PATH = './checkpoint'\n",
        "MODEL_NAME = 'vit_base_patch16_224'\n",
        "num_classes = 10\n",
        "EPOCHS = 5\n",
        "LR = 0.0001\n",
        "WD = 0.0\n",
        "shots = 1000\n",
        "\n",
        "print(f\"Creating model: {MODEL_NAME}\")\n",
        "model = create_model(\n",
        "        MODEL_NAME,\n",
        "        pretrained=False,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "cifar10_training_loader = get_training_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=2,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    shots=shots\n",
        ")\n",
        "\n",
        "assert (shots*num_classes == len(cifar10_training_loader.dataset))\n",
        "\n",
        "cifar10_test_loader = get_test_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=4,\n",
        "    batch_size=256,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f51e2794",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f51e2794",
        "outputId": "8229b94d-4793-4a28-fecf-b0363c8130b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training for 5 epochs\n",
            "Epoch: [1]  [  0/625]  eta: 0:12:02  loss: 6.8875 (6.8875)  time: 1.1564  data: 0.1729  max mem: 2096\n",
            "Epoch: [1]  [100/625]  eta: 0:01:36  loss: 2.1863 (2.5013)  time: 0.1718  data: 0.0049  max mem: 3065\n",
            "Epoch: [1]  [200/625]  eta: 0:01:17  loss: 2.0443 (2.3014)  time: 0.1768  data: 0.0060  max mem: 3065\n",
            "Epoch: [1]  [300/625]  eta: 0:00:59  loss: 2.0471 (2.2176)  time: 0.1782  data: 0.0048  max mem: 3065\n",
            "Epoch: [1]  [400/625]  eta: 0:00:40  loss: 2.0320 (2.1723)  time: 0.1870  data: 0.0075  max mem: 3065\n",
            "Epoch: [1]  [500/625]  eta: 0:00:22  loss: 1.9226 (2.1359)  time: 0.1852  data: 0.0048  max mem: 3065\n",
            "Epoch: [1]  [600/625]  eta: 0:00:04  loss: 1.9641 (2.1090)  time: 0.1850  data: 0.0070  max mem: 3065\n",
            "Epoch: [1]  [624/625]  eta: 0:00:00  loss: 1.8869 (2.1024)  time: 0.1813  data: 0.0050  max mem: 3065\n",
            "Epoch: [1] Total time: 0:01:54 (0.1829 s / it)\n",
            "Epoch: [1] Training Accuracy: 23.53%\n",
            "Averaged stats: loss: 1.8869 (2.1024)\n",
            "Epoch: [2]  [  0/625]  eta: 0:03:17  loss: 1.8860 (1.8860)  time: 0.3156  data: 0.1284  max mem: 3065\n",
            "Epoch: [2]  [100/625]  eta: 0:01:36  loss: 1.9312 (1.9422)  time: 0.1797  data: 0.0048  max mem: 3065\n",
            "Epoch: [2]  [200/625]  eta: 0:01:18  loss: 1.8752 (1.9227)  time: 0.1845  data: 0.0069  max mem: 3065\n",
            "Epoch: [2]  [300/625]  eta: 0:00:59  loss: 1.8728 (1.9113)  time: 0.1825  data: 0.0049  max mem: 3065\n",
            "Epoch: [2]  [400/625]  eta: 0:00:41  loss: 1.8880 (1.8985)  time: 0.1893  data: 0.0100  max mem: 3065\n",
            "Epoch: [2]  [500/625]  eta: 0:00:22  loss: 1.7893 (1.8900)  time: 0.1831  data: 0.0055  max mem: 3065\n",
            "Epoch: [2]  [600/625]  eta: 0:00:04  loss: 1.7373 (1.8833)  time: 0.1846  data: 0.0074  max mem: 3065\n",
            "Epoch: [2]  [624/625]  eta: 0:00:00  loss: 1.8142 (1.8827)  time: 0.1807  data: 0.0049  max mem: 3065\n",
            "Epoch: [2] Total time: 0:01:54 (0.1838 s / it)\n",
            "Epoch: [2] Training Accuracy: 28.79%\n",
            "Averaged stats: loss: 1.8142 (1.8827)\n",
            "Epoch: [3]  [  0/625]  eta: 0:03:14  loss: 1.8587 (1.8587)  time: 0.3118  data: 0.1203  max mem: 3065\n",
            "Epoch: [3]  [100/625]  eta: 0:01:37  loss: 1.7405 (1.8136)  time: 0.1815  data: 0.0046  max mem: 3065\n",
            "Epoch: [3]  [200/625]  eta: 0:01:18  loss: 1.8345 (1.8272)  time: 0.1894  data: 0.0104  max mem: 3065\n",
            "Epoch: [3]  [300/625]  eta: 0:01:00  loss: 1.8250 (1.8141)  time: 0.1823  data: 0.0051  max mem: 3065\n",
            "Epoch: [3]  [400/625]  eta: 0:00:41  loss: 1.6486 (1.8091)  time: 0.1859  data: 0.0077  max mem: 3065\n",
            "Epoch: [3]  [500/625]  eta: 0:00:23  loss: 1.7857 (1.8025)  time: 0.1811  data: 0.0047  max mem: 3065\n",
            "Epoch: [3]  [600/625]  eta: 0:00:04  loss: 1.7685 (1.7967)  time: 0.1864  data: 0.0084  max mem: 3065\n",
            "Epoch: [3]  [624/625]  eta: 0:00:00  loss: 1.7132 (1.7964)  time: 0.1813  data: 0.0045  max mem: 3065\n",
            "Epoch: [3] Total time: 0:01:55 (0.1845 s / it)\n",
            "Epoch: [3] Training Accuracy: 33.04%\n",
            "Averaged stats: loss: 1.7132 (1.7964)\n",
            "Epoch: [4]  [  0/625]  eta: 0:03:24  loss: 2.1947 (2.1947)  time: 0.3278  data: 0.1451  max mem: 3065\n",
            "Epoch: [4]  [100/625]  eta: 0:01:36  loss: 1.7778 (1.7549)  time: 0.1824  data: 0.0061  max mem: 3065\n",
            "Epoch: [4]  [200/625]  eta: 0:01:18  loss: 1.7155 (1.7445)  time: 0.1821  data: 0.0052  max mem: 3065\n",
            "Epoch: [4]  [300/625]  eta: 0:00:59  loss: 1.6985 (1.7390)  time: 0.1823  data: 0.0053  max mem: 3065\n",
            "Epoch: [4]  [400/625]  eta: 0:00:41  loss: 1.7427 (1.7383)  time: 0.1894  data: 0.0100  max mem: 3065\n",
            "Epoch: [4]  [500/625]  eta: 0:00:22  loss: 1.8004 (1.7370)  time: 0.1825  data: 0.0052  max mem: 3065\n",
            "Epoch: [4]  [600/625]  eta: 0:00:04  loss: 1.6970 (1.7301)  time: 0.1825  data: 0.0053  max mem: 3065\n",
            "Epoch: [4]  [624/625]  eta: 0:00:00  loss: 1.6780 (1.7309)  time: 0.1840  data: 0.0068  max mem: 3065\n",
            "Epoch: [4] Total time: 0:01:54 (0.1838 s / it)\n",
            "Epoch: [4] Training Accuracy: 34.71%\n",
            "Averaged stats: loss: 1.6780 (1.7309)\n",
            "Epoch: [5]  [  0/625]  eta: 0:03:12  loss: 1.4033 (1.4033)  time: 0.3072  data: 0.1282  max mem: 3065\n",
            "Epoch: [5]  [100/625]  eta: 0:01:36  loss: 1.6654 (1.7020)  time: 0.1823  data: 0.0049  max mem: 3065\n",
            "Epoch: [5]  [200/625]  eta: 0:01:18  loss: 1.7404 (1.6785)  time: 0.1889  data: 0.0105  max mem: 3065\n",
            "Epoch: [5]  [300/625]  eta: 0:00:59  loss: 1.6537 (1.6721)  time: 0.1855  data: 0.0074  max mem: 3065\n",
            "Epoch: [5]  [400/625]  eta: 0:00:41  loss: 1.6392 (1.6754)  time: 0.1867  data: 0.0094  max mem: 3065\n",
            "Epoch: [5]  [500/625]  eta: 0:00:22  loss: 1.7085 (1.6753)  time: 0.1823  data: 0.0049  max mem: 3065\n",
            "Epoch: [5]  [600/625]  eta: 0:00:04  loss: 1.6666 (1.6768)  time: 0.1840  data: 0.0069  max mem: 3065\n",
            "Epoch: [5]  [624/625]  eta: 0:00:00  loss: 1.6972 (1.6776)  time: 0.1835  data: 0.0068  max mem: 3065\n",
            "Epoch: [5] Total time: 0:01:55 (0.1841 s / it)\n",
            "Epoch: [5] Training Accuracy: 37.44%\n",
            "Averaged stats: loss: 1.6972 (1.6776)\n",
            "Test:  [ 0/40]  eta: 0:02:02  loss: 1.6280 (1.6280)  acc1: 38.2812 (38.2812)  acc5: 91.0156 (91.0156)  time: 3.0623  data: 1.7089  max mem: 3156\n",
            "Test:  [20/40]  eta: 0:00:23  loss: 1.6459 (1.6371)  acc1: 38.2812 (38.1324)  acc5: 89.4531 (89.7879)  time: 1.0565  data: 0.0841  max mem: 3156\n",
            "Test:  [39/40]  eta: 0:00:01  loss: 1.6502 (1.6464)  acc1: 38.6719 (38.2600)  acc5: 88.6719 (89.1000)  time: 0.9589  data: 0.0498  max mem: 3156\n",
            "Test: Total time: 0:00:42 (1.0589 s / it)\n",
            "* Acc@1 38.260 Acc@5 89.100 loss 1.646\n",
            "Accuracy of the network on the 40 test images: 38.3%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Start training for {EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, cifar10_training_loader,\n",
        "        optimizer, device, epoch)\n",
        "    if epoch % 10 == 9:\n",
        "        test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "        print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2d48bd9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d48bd9a",
        "outputId": "0aabeb49-b6e9-4520-a13e-6f1a7a0b7220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:  [ 0/40]  eta: 0:01:44  loss: 1.6280 (1.6280)  acc1: 38.2812 (38.2812)  acc5: 91.0156 (91.0156)  time: 2.6090  data: 1.5375  max mem: 3156\n",
            "Test:  [20/40]  eta: 0:00:22  loss: 1.6459 (1.6371)  acc1: 38.2812 (38.1324)  acc5: 89.4531 (89.7879)  time: 1.0650  data: 0.0889  max mem: 3156\n",
            "Test:  [39/40]  eta: 0:00:01  loss: 1.6502 (1.6464)  acc1: 38.6719 (38.2600)  acc5: 88.6719 (89.1000)  time: 0.9484  data: 0.0540  max mem: 3156\n",
            "Test: Total time: 0:00:41 (1.0459 s / it)\n",
            "* Acc@1 38.260 Acc@5 89.100 loss 1.646\n",
            "Throughput: 238.9909673432086\n"
          ]
        }
      ],
      "source": [
        "# Calculate througput\n",
        "start_time = time.time()\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "end_time = time.time()\n",
        "num_samples = len(cifar10_test_loader.dataset)\n",
        "throughput = num_samples / (end_time - start_time)\n",
        "print(\"Throughput: {}\".format(throughput))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61fdc53f",
      "metadata": {
        "id": "61fdc53f"
      },
      "source": [
        "# Q2 Fine-tuning Pretrained ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ee8523be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee8523be",
        "outputId": "9fc9a743-fd88-49b2-8f31-b3e9d99758cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: vit_base_patch16_224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\" to /root/.cache/torch/hub/checkpoints/deit_base_patch16_224-b5f2ef4d.pth\n",
            "100%|██████████| 330M/330M [00:01<00:00, 179MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "number of params: 85806346\n"
          ]
        }
      ],
      "source": [
        "MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "CHECKPOINT_PATH = './checkpoint'\n",
        "MODEL_NAME = 'vit_base_patch16_224'\n",
        "num_classes = 10\n",
        "EPOCHS = 5\n",
        "LR = 0.0001\n",
        "WD = 0.0\n",
        "shots = 1000\n",
        "\n",
        "print(f\"Creating model: {MODEL_NAME}\")\n",
        "model = create_model(\n",
        "        MODEL_NAME,\n",
        "        pretrained=True,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "cifar10_training_loader = get_training_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=2,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    shots=shots\n",
        ")\n",
        "\n",
        "assert (shots*num_classes == len(cifar10_training_loader.dataset))\n",
        "\n",
        "cifar10_test_loader = get_test_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=4,\n",
        "    batch_size=256,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f881d0c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f881d0c0",
        "outputId": "c94e6c43-84d7-4ab3-9b4b-0a854201545a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training for 5 epochs\n",
            "Epoch: [1]  [  0/625]  eta: 0:04:40  loss: 2.2632 (2.2632)  time: 0.4489  data: 0.1838  max mem: 3156\n",
            "Epoch: [1]  [100/625]  eta: 0:01:38  loss: 2.1144 (2.2261)  time: 0.1855  data: 0.0051  max mem: 3156\n",
            "Epoch: [1]  [200/625]  eta: 0:01:19  loss: 1.9214 (2.1336)  time: 0.1842  data: 0.0048  max mem: 3156\n",
            "Epoch: [1]  [300/625]  eta: 0:01:00  loss: 1.8683 (2.0609)  time: 0.1920  data: 0.0105  max mem: 3156\n",
            "Epoch: [1]  [400/625]  eta: 0:00:42  loss: 1.6490 (1.9844)  time: 0.1822  data: 0.0047  max mem: 3156\n",
            "Epoch: [1]  [500/625]  eta: 0:00:23  loss: 1.3657 (1.9079)  time: 0.1886  data: 0.0074  max mem: 3156\n",
            "Epoch: [1]  [600/625]  eta: 0:00:04  loss: 1.3566 (1.8288)  time: 0.1847  data: 0.0048  max mem: 3156\n",
            "Epoch: [1]  [624/625]  eta: 0:00:00  loss: 1.3284 (1.8111)  time: 0.1904  data: 0.0091  max mem: 3156\n",
            "Epoch: [1] Total time: 0:01:57 (0.1874 s / it)\n",
            "Epoch: [1] Training Accuracy: 32.97%\n",
            "Averaged stats: loss: 1.3284 (1.8111)\n",
            "Epoch: [2]  [  0/625]  eta: 0:03:34  loss: 0.8977 (0.8977)  time: 0.3437  data: 0.1569  max mem: 3156\n",
            "Epoch: [2]  [100/625]  eta: 0:01:39  loss: 1.1697 (1.2273)  time: 0.1836  data: 0.0047  max mem: 3156\n",
            "Epoch: [2]  [200/625]  eta: 0:01:19  loss: 1.0741 (1.1804)  time: 0.1912  data: 0.0103  max mem: 3156\n",
            "Epoch: [2]  [300/625]  eta: 0:01:00  loss: 0.9393 (1.1276)  time: 0.1840  data: 0.0050  max mem: 3156\n",
            "Epoch: [2]  [400/625]  eta: 0:00:42  loss: 0.9051 (1.0827)  time: 0.1883  data: 0.0082  max mem: 3156\n",
            "Epoch: [2]  [500/625]  eta: 0:00:23  loss: 0.8419 (1.0365)  time: 0.1844  data: 0.0054  max mem: 3156\n",
            "Epoch: [2]  [600/625]  eta: 0:00:04  loss: 0.7173 (1.0057)  time: 0.1839  data: 0.0049  max mem: 3156\n",
            "Epoch: [2]  [624/625]  eta: 0:00:00  loss: 0.8608 (1.0018)  time: 0.1901  data: 0.0105  max mem: 3156\n",
            "Epoch: [2] Total time: 0:01:56 (0.1869 s / it)\n",
            "Epoch: [2] Training Accuracy: 64.37%\n",
            "Averaged stats: loss: 0.8608 (1.0018)\n",
            "Epoch: [3]  [  0/625]  eta: 0:03:38  loss: 0.9742 (0.9742)  time: 0.3489  data: 0.1558  max mem: 3156\n",
            "Epoch: [3]  [100/625]  eta: 0:01:37  loss: 0.7023 (0.6988)  time: 0.1843  data: 0.0053  max mem: 3156\n",
            "Epoch: [3]  [200/625]  eta: 0:01:19  loss: 0.6893 (0.6938)  time: 0.1913  data: 0.0091  max mem: 3156\n",
            "Epoch: [3]  [300/625]  eta: 0:01:00  loss: 0.4921 (0.6649)  time: 0.1842  data: 0.0052  max mem: 3156\n",
            "Epoch: [3]  [400/625]  eta: 0:00:42  loss: 0.6067 (0.6603)  time: 0.1901  data: 0.0082  max mem: 3156\n",
            "Epoch: [3]  [500/625]  eta: 0:00:23  loss: 0.5757 (0.6490)  time: 0.1830  data: 0.0049  max mem: 3156\n",
            "Epoch: [3]  [600/625]  eta: 0:00:04  loss: 0.5367 (0.6364)  time: 0.1889  data: 0.0074  max mem: 3156\n",
            "Epoch: [3]  [624/625]  eta: 0:00:00  loss: 0.8447 (0.6429)  time: 0.1852  data: 0.0055  max mem: 3156\n",
            "Epoch: [3] Total time: 0:01:56 (0.1867 s / it)\n",
            "Epoch: [3] Training Accuracy: 77.47%\n",
            "Averaged stats: loss: 0.8447 (0.6429)\n",
            "Epoch: [4]  [  0/625]  eta: 0:03:36  loss: 0.2905 (0.2905)  time: 0.3464  data: 0.1713  max mem: 3156\n",
            "Epoch: [4]  [100/625]  eta: 0:01:38  loss: 0.4208 (0.4475)  time: 0.1841  data: 0.0050  max mem: 3156\n",
            "Epoch: [4]  [200/625]  eta: 0:01:19  loss: 0.4813 (0.4598)  time: 0.1865  data: 0.0065  max mem: 3156\n",
            "Epoch: [4]  [300/625]  eta: 0:01:00  loss: 0.4166 (0.4623)  time: 0.1841  data: 0.0049  max mem: 3156\n",
            "Epoch: [4]  [400/625]  eta: 0:00:41  loss: 0.3980 (0.4662)  time: 0.1896  data: 0.0088  max mem: 3156\n",
            "Epoch: [4]  [500/625]  eta: 0:00:23  loss: 0.3240 (0.4579)  time: 0.1830  data: 0.0048  max mem: 3156\n",
            "Epoch: [4]  [600/625]  eta: 0:00:04  loss: 0.3615 (0.4543)  time: 0.1865  data: 0.0070  max mem: 3156\n",
            "Epoch: [4]  [624/625]  eta: 0:00:00  loss: 0.3684 (0.4543)  time: 0.1863  data: 0.0068  max mem: 3156\n",
            "Epoch: [4] Total time: 0:01:56 (0.1859 s / it)\n",
            "Epoch: [4] Training Accuracy: 84.21%\n",
            "Averaged stats: loss: 0.3684 (0.4543)\n",
            "Epoch: [5]  [  0/625]  eta: 0:03:30  loss: 0.2366 (0.2366)  time: 0.3366  data: 0.1523  max mem: 3156\n",
            "Epoch: [5]  [100/625]  eta: 0:01:37  loss: 0.2281 (0.3079)  time: 0.1834  data: 0.0058  max mem: 3156\n",
            "Epoch: [5]  [200/625]  eta: 0:01:18  loss: 0.3411 (0.3332)  time: 0.1840  data: 0.0052  max mem: 3156\n",
            "Epoch: [5]  [300/625]  eta: 0:01:00  loss: 0.3451 (0.3345)  time: 0.1836  data: 0.0051  max mem: 3156\n",
            "Epoch: [5]  [400/625]  eta: 0:00:41  loss: 0.2619 (0.3420)  time: 0.1890  data: 0.0076  max mem: 3156\n",
            "Epoch: [5]  [500/625]  eta: 0:00:23  loss: 0.3557 (0.3444)  time: 0.1831  data: 0.0050  max mem: 3156\n",
            "Epoch: [5]  [600/625]  eta: 0:00:04  loss: 0.3297 (0.3438)  time: 0.1897  data: 0.0092  max mem: 3156\n",
            "Epoch: [5]  [624/625]  eta: 0:00:00  loss: 0.3173 (0.3474)  time: 0.1831  data: 0.0050  max mem: 3156\n",
            "Epoch: [5] Total time: 0:01:55 (0.1853 s / it)\n",
            "Epoch: [5] Training Accuracy: 87.74%\n",
            "Averaged stats: loss: 0.3173 (0.3474)\n",
            "Test:  [ 0/40]  eta: 0:02:37  loss: 0.6096 (0.6096)  acc1: 77.7344 (77.7344)  acc5: 99.2188 (99.2188)  time: 3.9347  data: 2.8098  max mem: 3156\n",
            "Test:  [20/40]  eta: 0:00:24  loss: 0.5715 (0.5838)  acc1: 80.8594 (80.6362)  acc5: 98.8281 (98.9211)  time: 1.0868  data: 0.0923  max mem: 3156\n",
            "Test:  [39/40]  eta: 0:00:01  loss: 0.5826 (0.5795)  acc1: 80.0781 (80.3900)  acc5: 99.2188 (99.0800)  time: 0.9719  data: 0.0478  max mem: 3156\n",
            "Test: Total time: 0:00:44 (1.1059 s / it)\n",
            "* Acc@1 80.390 Acc@5 99.080 loss 0.579\n",
            "Accuracy of the network on the 40 test images: 80.4%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Start training for {EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, cifar10_training_loader,\n",
        "        optimizer, device, epoch)\n",
        "    if epoch % 10 == 9:\n",
        "        test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "        print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e323d040",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e323d040",
        "outputId": "d980ff40-c7aa-4a31-b576-d067fb8f21ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:  [ 0/40]  eta: 0:02:12  loss: 0.6096 (0.6096)  acc1: 77.7344 (77.7344)  acc5: 99.2188 (99.2188)  time: 3.3081  data: 2.1698  max mem: 3156\n",
            "Test:  [20/40]  eta: 0:00:23  loss: 0.5715 (0.5838)  acc1: 80.8594 (80.6362)  acc5: 98.8281 (98.9211)  time: 1.0619  data: 0.0785  max mem: 3156\n",
            "Test:  [39/40]  eta: 0:00:01  loss: 0.5826 (0.5795)  acc1: 80.0781 (80.3900)  acc5: 99.2188 (99.0800)  time: 0.9607  data: 0.0468  max mem: 3156\n",
            "Test: Total time: 0:00:42 (1.0732 s / it)\n",
            "* Acc@1 80.390 Acc@5 99.080 loss 0.579\n",
            "Throughput: 232.89691721747135\n"
          ]
        }
      ],
      "source": [
        "# Calculate througput\n",
        "start_time = time.time()\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "end_time = time.time()\n",
        "num_samples = len(cifar10_test_loader.dataset)\n",
        "throughput = num_samples / (end_time - start_time)\n",
        "print(\"Throughput: {}\".format(throughput))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93beb48",
      "metadata": {
        "id": "a93beb48"
      },
      "source": [
        "# Q3 ViT model on a small device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dcb0666d",
      "metadata": {
        "id": "dcb0666d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d7d2c9-eea7-455e-f872-cc4c2ead89d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: vit_tiny_patch16_224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth\" to /root/.cache/torch/hub/checkpoints/deit_tiny_patch16_224-a1311bcf.pth\n",
            "100%|██████████| 21.9M/21.9M [00:00<00:00, 134MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "number of params: 5526346\n"
          ]
        }
      ],
      "source": [
        "MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "CHECKPOINT_PATH = './checkpoint'\n",
        "MODEL_NAME = 'vit_tiny_patch16_224'\n",
        "num_classes = 10\n",
        "EPOCHS = 5\n",
        "LR = 0.0001\n",
        "WD = 0.0\n",
        "shots = 1000\n",
        "\n",
        "print(f\"Creating model: {MODEL_NAME}\")\n",
        "model = create_model(\n",
        "        MODEL_NAME,\n",
        "        pretrained=True,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "cifar10_training_loader = get_training_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=2,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    shots=shots\n",
        ")\n",
        "\n",
        "assert (shots*num_classes == len(cifar10_training_loader.dataset))\n",
        "\n",
        "cifar10_test_loader = get_test_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=4,\n",
        "    batch_size=256,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "138b86de",
      "metadata": {
        "id": "138b86de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6048e69-f572-4c85-e83a-3670920b757e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training for 5 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1]  [  0/625]  eta: 0:03:05  loss: 2.3241 (2.3241)  time: 0.2961  data: 0.1723  max mem: 3156\n",
            "Epoch: [1]  [100/625]  eta: 0:00:30  loss: 2.2290 (2.2492)  time: 0.0554  data: 0.0047  max mem: 3156\n",
            "Epoch: [1]  [200/625]  eta: 0:00:26  loss: 1.9586 (2.1558)  time: 0.0637  data: 0.0067  max mem: 3156\n",
            "Epoch: [1]  [300/625]  eta: 0:00:19  loss: 1.8633 (2.0821)  time: 0.0561  data: 0.0050  max mem: 3156\n",
            "Epoch: [1]  [400/625]  eta: 0:00:13  loss: 1.7633 (2.0298)  time: 0.0854  data: 0.0110  max mem: 3156\n",
            "Epoch: [1]  [500/625]  eta: 0:00:07  loss: 1.5799 (1.9757)  time: 0.0548  data: 0.0046  max mem: 3156\n",
            "Epoch: [1]  [600/625]  eta: 0:00:01  loss: 1.4734 (1.9215)  time: 0.0923  data: 0.0134  max mem: 3156\n",
            "Epoch: [1]  [624/625]  eta: 0:00:00  loss: 1.4968 (1.9079)  time: 0.0565  data: 0.0058  max mem: 3156\n",
            "Epoch: [1] Total time: 0:00:39 (0.0627 s / it)\n",
            "Epoch: [1] Training Accuracy: 27.69%\n",
            "Averaged stats: loss: 1.4968 (1.9079)\n",
            "Epoch: [2]  [  0/625]  eta: 0:02:42  loss: 1.4784 (1.4784)  time: 0.2593  data: 0.1598  max mem: 3156\n",
            "Epoch: [2]  [100/625]  eta: 0:00:30  loss: 1.4969 (1.5201)  time: 0.0559  data: 0.0047  max mem: 3156\n",
            "Epoch: [2]  [200/625]  eta: 0:00:26  loss: 1.3246 (1.4724)  time: 0.0758  data: 0.0091  max mem: 3156\n",
            "Epoch: [2]  [300/625]  eta: 0:00:19  loss: 1.2821 (1.4308)  time: 0.0541  data: 0.0047  max mem: 3156\n",
            "Epoch: [2]  [400/625]  eta: 0:00:13  loss: 1.1547 (1.3840)  time: 0.0872  data: 0.0125  max mem: 3156\n",
            "Epoch: [2]  [500/625]  eta: 0:00:07  loss: 1.1677 (1.3431)  time: 0.0546  data: 0.0051  max mem: 3156\n",
            "Epoch: [2]  [600/625]  eta: 0:00:01  loss: 1.1592 (1.3142)  time: 0.0753  data: 0.0098  max mem: 3156\n",
            "Epoch: [2]  [624/625]  eta: 0:00:00  loss: 1.0124 (1.3068)  time: 0.0794  data: 0.0108  max mem: 3156\n",
            "Epoch: [2] Total time: 0:00:37 (0.0605 s / it)\n",
            "Epoch: [2] Training Accuracy: 52.67%\n",
            "Averaged stats: loss: 1.0124 (1.3068)\n",
            "Epoch: [3]  [  0/625]  eta: 0:02:35  loss: 1.0507 (1.0507)  time: 0.2487  data: 0.1558  max mem: 3156\n",
            "Epoch: [3]  [100/625]  eta: 0:00:29  loss: 1.1635 (1.0352)  time: 0.0546  data: 0.0046  max mem: 3156\n",
            "Epoch: [3]  [200/625]  eta: 0:00:25  loss: 0.9074 (1.0150)  time: 0.0844  data: 0.0123  max mem: 3156\n",
            "Epoch: [3]  [300/625]  eta: 0:00:19  loss: 1.0253 (1.0140)  time: 0.0547  data: 0.0050  max mem: 3156\n",
            "Epoch: [3]  [400/625]  eta: 0:00:13  loss: 0.9174 (0.9920)  time: 0.0668  data: 0.0061  max mem: 3156\n",
            "Epoch: [3]  [500/625]  eta: 0:00:07  loss: 0.8890 (0.9755)  time: 0.0550  data: 0.0050  max mem: 3156\n",
            "Epoch: [3]  [600/625]  eta: 0:00:01  loss: 0.7954 (0.9658)  time: 0.0556  data: 0.0050  max mem: 3156\n",
            "Epoch: [3]  [624/625]  eta: 0:00:00  loss: 0.8141 (0.9617)  time: 0.0753  data: 0.0092  max mem: 3156\n",
            "Epoch: [3] Total time: 0:00:37 (0.0598 s / it)\n",
            "Epoch: [3] Training Accuracy: 65.82%\n",
            "Averaged stats: loss: 0.8141 (0.9617)\n",
            "Epoch: [4]  [  0/625]  eta: 0:03:28  loss: 0.6545 (0.6545)  time: 0.3334  data: 0.2055  max mem: 3156\n",
            "Epoch: [4]  [100/625]  eta: 0:00:32  loss: 0.7703 (0.8413)  time: 0.0534  data: 0.0049  max mem: 3156\n",
            "Epoch: [4]  [200/625]  eta: 0:00:25  loss: 0.6782 (0.8349)  time: 0.0622  data: 0.0064  max mem: 3156\n",
            "Epoch: [4]  [300/625]  eta: 0:00:19  loss: 0.7669 (0.8173)  time: 0.0540  data: 0.0047  max mem: 3156\n",
            "Epoch: [4]  [400/625]  eta: 0:00:13  loss: 0.7304 (0.8005)  time: 0.0548  data: 0.0049  max mem: 3156\n",
            "Epoch: [4]  [500/625]  eta: 0:00:07  loss: 0.5972 (0.7873)  time: 0.0573  data: 0.0057  max mem: 3156\n",
            "Epoch: [4]  [600/625]  eta: 0:00:01  loss: 0.6409 (0.7856)  time: 0.0558  data: 0.0057  max mem: 3156\n",
            "Epoch: [4]  [624/625]  eta: 0:00:00  loss: 0.7340 (0.7841)  time: 0.0525  data: 0.0048  max mem: 3156\n",
            "Epoch: [4] Total time: 0:00:37 (0.0597 s / it)\n",
            "Epoch: [4] Training Accuracy: 72.41%\n",
            "Averaged stats: loss: 0.7340 (0.7841)\n",
            "Epoch: [5]  [  0/625]  eta: 0:03:53  loss: 0.4203 (0.4203)  time: 0.3737  data: 0.2569  max mem: 3156\n",
            "Epoch: [5]  [100/625]  eta: 0:00:41  loss: 0.7668 (0.6350)  time: 0.0552  data: 0.0047  max mem: 3156\n",
            "Epoch: [5]  [200/625]  eta: 0:00:28  loss: 0.5961 (0.6596)  time: 0.0543  data: 0.0046  max mem: 3156\n",
            "Epoch: [5]  [300/625]  eta: 0:00:21  loss: 0.5858 (0.6619)  time: 0.0546  data: 0.0050  max mem: 3156\n",
            "Epoch: [5]  [400/625]  eta: 0:00:14  loss: 0.6361 (0.6657)  time: 0.0544  data: 0.0048  max mem: 3156\n",
            "Epoch: [5]  [500/625]  eta: 0:00:08  loss: 0.6334 (0.6708)  time: 0.0542  data: 0.0050  max mem: 3156\n",
            "Epoch: [5]  [600/625]  eta: 0:00:01  loss: 0.6078 (0.6739)  time: 0.0541  data: 0.0048  max mem: 3156\n",
            "Epoch: [5]  [624/625]  eta: 0:00:00  loss: 0.6352 (0.6743)  time: 0.0514  data: 0.0044  max mem: 3156\n",
            "Epoch: [5] Total time: 0:00:39 (0.0624 s / it)\n",
            "Epoch: [5] Training Accuracy: 76.04%\n",
            "Averaged stats: loss: 0.6352 (0.6743)\n",
            "Test:  [ 0/40]  eta: 0:02:16  loss: 0.8062 (0.8062)  acc1: 73.4375 (73.4375)  acc5: 98.0469 (98.0469)  time: 3.4230  data: 2.9538  max mem: 3156\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.7798 (0.7825)  acc1: 72.6562 (73.3259)  acc5: 98.4375 (98.3631)  time: 0.4360  data: 0.1464  max mem: 3156\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.7851 (0.7798)  acc1: 72.6562 (73.1600)  acc5: 98.4375 (98.3500)  time: 0.4172  data: 0.1486  max mem: 3156\n",
            "Test: Total time: 0:00:20 (0.5028 s / it)\n",
            "* Acc@1 73.160 Acc@5 98.350 loss 0.780\n",
            "Accuracy of the network on the 40 test images: 73.2%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Start training for {EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, cifar10_training_loader,\n",
        "        optimizer, device, epoch)\n",
        "    if epoch % 10 == 9:\n",
        "        test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "        print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "199e33f5",
      "metadata": {
        "id": "199e33f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c3e29a-cab2-438e-d1c9-7ea049c419ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:  [ 0/40]  eta: 0:01:32  loss: 0.8062 (0.8062)  acc1: 73.4375 (73.4375)  acc5: 98.0469 (98.0469)  time: 2.3161  data: 1.9110  max mem: 3156\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.7798 (0.7825)  acc1: 72.6562 (73.3259)  acc5: 98.4375 (98.3631)  time: 0.4887  data: 0.1797  max mem: 3156\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.7851 (0.7798)  acc1: 72.6562 (73.1600)  acc5: 98.4375 (98.3500)  time: 0.3562  data: 0.1108  max mem: 3156\n",
            "Test: Total time: 0:00:18 (0.4709 s / it)\n",
            "* Acc@1 73.160 Acc@5 98.350 loss 0.780\n",
            "Throughput: 530.8179297502885\n"
          ]
        }
      ],
      "source": [
        "# Calculate througput\n",
        "start_time = time.time()\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "end_time = time.time()\n",
        "num_samples = len(cifar10_test_loader.dataset)\n",
        "throughput = num_samples / (end_time - start_time)\n",
        "print(\"Throughput: {}\".format(throughput))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33816cf2",
      "metadata": {
        "id": "33816cf2"
      },
      "source": [
        "# Q4 Knowledge Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "caaf4f8a",
      "metadata": {
        "id": "caaf4f8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f35d991-30a7-4e2c-ac60-01f66b3bd761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: vit_base_patch16_224\n",
            "number of params: 85806346\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Train the teacher\n",
        "MODEL_NAME = 'vit_base_patch16_224'\n",
        "num_classes = 10\n",
        "EPOCHS = 5\n",
        "LR = 0.0001\n",
        "WD = 0.0\n",
        "\n",
        "print(f\"Creating model: {MODEL_NAME}\")\n",
        "teacher = create_model(\n",
        "        MODEL_NAME,\n",
        "        pretrained=True,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "teacher = teacher.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(teacher.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "n_parameters = sum(p.numel() for p in teacher.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6c392f94",
      "metadata": {
        "id": "6c392f94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93cc0347-2085-490c-e48c-6433aa2bd81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training for 5 epochs\n",
            "Epoch: [1]  [  0/625]  eta: 0:04:20  loss: 2.4588 (2.4588)  time: 0.4176  data: 0.1720  max mem: 3156\n",
            "Epoch: [1]  [100/625]  eta: 0:01:40  loss: 1.9478 (2.1220)  time: 0.1913  data: 0.0069  max mem: 3156\n",
            "Epoch: [1]  [200/625]  eta: 0:01:20  loss: 1.4271 (1.8895)  time: 0.1855  data: 0.0048  max mem: 3156\n",
            "Epoch: [1]  [300/625]  eta: 0:01:01  loss: 1.0312 (1.6797)  time: 0.1909  data: 0.0107  max mem: 3156\n",
            "Epoch: [1]  [400/625]  eta: 0:00:42  loss: 0.9570 (1.5365)  time: 0.1832  data: 0.0049  max mem: 3156\n",
            "Epoch: [1]  [500/625]  eta: 0:00:23  loss: 0.8266 (1.4257)  time: 0.1922  data: 0.0101  max mem: 3156\n",
            "Epoch: [1]  [600/625]  eta: 0:00:04  loss: 0.6655 (1.3293)  time: 0.1867  data: 0.0050  max mem: 3156\n",
            "Epoch: [1]  [624/625]  eta: 0:00:00  loss: 0.8220 (1.3121)  time: 0.1864  data: 0.0048  max mem: 3156\n",
            "Epoch: [1] Total time: 0:01:57 (0.1880 s / it)\n",
            "Epoch: [1] Training Accuracy: 52.63%\n",
            "Averaged stats: loss: 0.8220 (1.3121)\n",
            "Epoch: [2]  [  0/625]  eta: 0:04:08  loss: 0.3830 (0.3830)  time: 0.3983  data: 0.1849  max mem: 3156\n",
            "Epoch: [2]  [100/625]  eta: 0:01:39  loss: 0.6202 (0.6536)  time: 0.1842  data: 0.0049  max mem: 3156\n",
            "Epoch: [2]  [200/625]  eta: 0:01:19  loss: 0.6682 (0.6987)  time: 0.1828  data: 0.0047  max mem: 3156\n",
            "Epoch: [2]  [300/625]  eta: 0:01:00  loss: 0.6925 (0.6887)  time: 0.1922  data: 0.0096  max mem: 3156\n",
            "Epoch: [2]  [400/625]  eta: 0:00:42  loss: 0.5822 (0.6727)  time: 0.1852  data: 0.0051  max mem: 3156\n",
            "Epoch: [2]  [500/625]  eta: 0:00:23  loss: 0.5655 (0.6579)  time: 0.1885  data: 0.0075  max mem: 3156\n",
            "Epoch: [2]  [600/625]  eta: 0:00:04  loss: 0.7863 (0.6506)  time: 0.1837  data: 0.0049  max mem: 3156\n",
            "Epoch: [2]  [624/625]  eta: 0:00:00  loss: 0.5076 (0.6482)  time: 0.1895  data: 0.0082  max mem: 3156\n",
            "Epoch: [2] Total time: 0:01:56 (0.1869 s / it)\n",
            "Epoch: [2] Training Accuracy: 77.66%\n",
            "Averaged stats: loss: 0.5076 (0.6482)\n",
            "Epoch: [3]  [  0/625]  eta: 0:03:41  loss: 0.3335 (0.3335)  time: 0.3546  data: 0.1729  max mem: 3156\n",
            "Epoch: [3]  [100/625]  eta: 0:01:37  loss: 0.4130 (0.4859)  time: 0.1841  data: 0.0054  max mem: 3156\n",
            "Epoch: [3]  [200/625]  eta: 0:01:19  loss: 0.4410 (0.4916)  time: 0.1883  data: 0.0084  max mem: 3156\n",
            "Epoch: [3]  [300/625]  eta: 0:01:00  loss: 0.3538 (0.4807)  time: 0.1853  data: 0.0057  max mem: 3156\n",
            "Epoch: [3]  [400/625]  eta: 0:00:42  loss: 0.4228 (0.4748)  time: 0.1874  data: 0.0072  max mem: 3156\n",
            "Epoch: [3]  [500/625]  eta: 0:00:23  loss: 0.3188 (0.4734)  time: 0.1844  data: 0.0052  max mem: 3156\n",
            "Epoch: [3]  [600/625]  eta: 0:00:04  loss: 0.4580 (0.4685)  time: 0.1850  data: 0.0053  max mem: 3156\n",
            "Epoch: [3]  [624/625]  eta: 0:00:00  loss: 0.4289 (0.4668)  time: 0.1924  data: 0.0098  max mem: 3156\n",
            "Epoch: [3] Total time: 0:01:57 (0.1873 s / it)\n",
            "Epoch: [3] Training Accuracy: 83.66%\n",
            "Averaged stats: loss: 0.4289 (0.4668)\n",
            "Epoch: [4]  [  0/625]  eta: 0:03:47  loss: 0.2778 (0.2778)  time: 0.3639  data: 0.1652  max mem: 3156\n",
            "Epoch: [4]  [100/625]  eta: 0:01:37  loss: 0.2665 (0.3015)  time: 0.1836  data: 0.0055  max mem: 3156\n",
            "Epoch: [4]  [200/625]  eta: 0:01:19  loss: 0.2661 (0.3188)  time: 0.1906  data: 0.0087  max mem: 3156\n",
            "Epoch: [4]  [300/625]  eta: 0:01:00  loss: 0.2344 (0.3239)  time: 0.1842  data: 0.0054  max mem: 3156\n",
            "Epoch: [4]  [400/625]  eta: 0:00:41  loss: 0.3100 (0.3378)  time: 0.1846  data: 0.0057  max mem: 3156\n",
            "Epoch: [4]  [500/625]  eta: 0:00:23  loss: 0.3344 (0.3363)  time: 0.1849  data: 0.0059  max mem: 3156\n",
            "Epoch: [4]  [600/625]  eta: 0:00:04  loss: 0.4168 (0.3454)  time: 0.1852  data: 0.0057  max mem: 3156\n",
            "Epoch: [4]  [624/625]  eta: 0:00:00  loss: 0.2808 (0.3444)  time: 0.1927  data: 0.0101  max mem: 3156\n",
            "Epoch: [4] Total time: 0:01:56 (0.1870 s / it)\n",
            "Epoch: [4] Training Accuracy: 88.18%\n",
            "Averaged stats: loss: 0.2808 (0.3444)\n",
            "Epoch: [5]  [  0/625]  eta: 0:03:42  loss: 0.2554 (0.2554)  time: 0.3555  data: 0.1752  max mem: 3156\n",
            "Epoch: [5]  [100/625]  eta: 0:01:38  loss: 0.3645 (0.2581)  time: 0.1843  data: 0.0054  max mem: 3156\n",
            "Epoch: [5]  [200/625]  eta: 0:01:19  loss: 0.1948 (0.2610)  time: 0.1912  data: 0.0095  max mem: 3156\n",
            "Epoch: [5]  [300/625]  eta: 0:01:00  loss: 0.2294 (0.2629)  time: 0.1827  data: 0.0051  max mem: 3156\n",
            "Epoch: [5]  [400/625]  eta: 0:00:42  loss: 0.3087 (0.2717)  time: 0.1849  data: 0.0056  max mem: 3156\n",
            "Epoch: [5]  [500/625]  eta: 0:00:23  loss: 0.2248 (0.2713)  time: 0.1858  data: 0.0068  max mem: 3156\n",
            "Epoch: [5]  [600/625]  eta: 0:00:04  loss: 0.3291 (0.2764)  time: 0.1847  data: 0.0061  max mem: 3156\n",
            "Epoch: [5]  [624/625]  eta: 0:00:00  loss: 0.3047 (0.2789)  time: 0.1926  data: 0.0116  max mem: 3156\n",
            "Epoch: [5] Total time: 0:01:56 (0.1867 s / it)\n",
            "Epoch: [5] Training Accuracy: 90.26%\n",
            "Averaged stats: loss: 0.3047 (0.2789)\n",
            "Test:  [ 0/40]  eta: 0:02:10  loss: 0.5764 (0.5764)  acc1: 81.2500 (81.2500)  acc5: 99.2188 (99.2188)  time: 3.2621  data: 2.1898  max mem: 3184\n",
            "Test:  [20/40]  eta: 0:00:22  loss: 0.6046 (0.6022)  acc1: 80.8594 (81.2872)  acc5: 98.8281 (98.7909)  time: 1.0385  data: 0.0711  max mem: 3184\n",
            "Test:  [39/40]  eta: 0:00:01  loss: 0.5773 (0.5969)  acc1: 79.6875 (81.0300)  acc5: 98.8281 (98.8400)  time: 0.9829  data: 0.0566  max mem: 3184\n",
            "Test: Total time: 0:00:42 (1.0683 s / it)\n",
            "* Acc@1 81.030 Acc@5 98.840 loss 0.597\n",
            "Accuracy of the network on the 40 test images: 81.0%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Start training for {EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_stats = train_one_epoch(\n",
        "        teacher, criterion, cifar10_training_loader,\n",
        "        optimizer, device, epoch)\n",
        "    if epoch % 10 == 9:\n",
        "        test_stats = evaluate(cifar10_test_loader, teacher, criterion, device)\n",
        "        print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, teacher, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9ab509fd",
      "metadata": {
        "id": "9ab509fd"
      },
      "outputs": [],
      "source": [
        "# save finetuned teacher model\n",
        "torch.save(teacher.state_dict(), './teacher.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "69587aa8",
      "metadata": {
        "id": "69587aa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52cf1fdd-014a-4de1-f162-3dda8f9b3b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:  [ 0/40]  eta: 0:02:53  loss: 0.5764 (0.5764)  acc1: 81.2500 (81.2500)  acc5: 99.2188 (99.2188)  time: 4.3401  data: 3.1810  max mem: 3512\n",
            "Test:  [20/40]  eta: 0:00:24  loss: 0.6046 (0.6022)  acc1: 80.8594 (81.2872)  acc5: 98.8281 (98.7909)  time: 1.0940  data: 0.0651  max mem: 3512\n",
            "Test:  [39/40]  eta: 0:00:01  loss: 0.5773 (0.5969)  acc1: 79.6875 (81.0300)  acc5: 98.8281 (98.8400)  time: 1.0070  data: 0.0554  max mem: 3512\n",
            "Test: Total time: 0:00:45 (1.1347 s / it)\n",
            "* Acc@1 81.030 Acc@5 98.840 loss 0.597\n",
            "Accuracy of the network on the 40 test images: 81.0%\n",
            "number of params: 5526346\n",
            "Start training for 5 epochs\n",
            "Epoch: [1]  [  0/625]  eta: 0:03:13  loss: 3.0322 (3.0322)  time: 0.3098  data: 0.1962  max mem: 3512\n",
            "Epoch: [1]  [100/625]  eta: 0:00:56  loss: 2.1571 (2.2451)  time: 0.1201  data: 0.0094  max mem: 3512\n",
            "Epoch: [1]  [200/625]  eta: 0:00:44  loss: 1.7630 (2.1014)  time: 0.1020  data: 0.0047  max mem: 3512\n",
            "Epoch: [1]  [300/625]  eta: 0:00:34  loss: 1.5722 (1.9864)  time: 0.1020  data: 0.0049  max mem: 3512\n",
            "Epoch: [1]  [400/625]  eta: 0:00:23  loss: 1.4503 (1.8943)  time: 0.1024  data: 0.0052  max mem: 3512\n",
            "Epoch: [1]  [500/625]  eta: 0:00:13  loss: 1.3675 (1.8138)  time: 0.1030  data: 0.0049  max mem: 3512\n",
            "Epoch: [1]  [600/625]  eta: 0:00:02  loss: 1.2364 (1.7313)  time: 0.1163  data: 0.0075  max mem: 3512\n",
            "Epoch: [1]  [624/625]  eta: 0:00:00  loss: 1.1830 (1.7122)  time: 0.1024  data: 0.0047  max mem: 3512\n",
            "Epoch: [1] Total time: 0:01:06 (0.1071 s / it)\n",
            "Averaged stats: loss: 1.1830 (1.7122)\n",
            "Test:  [ 0/40]  eta: 0:01:33  loss: 1.3306 (1.3306)  acc1: 51.5625 (51.5625)  acc5: 94.9219 (94.9219)  time: 2.3420  data: 1.9689  max mem: 3512\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 1.2935 (1.2947)  acc1: 52.7344 (53.1808)  acc5: 95.7031 (95.4241)  time: 0.5022  data: 0.1935  max mem: 3512\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.2961 (1.2971)  acc1: 52.7344 (53.0200)  acc5: 95.7031 (95.4900)  time: 0.3740  data: 0.1145  max mem: 3512\n",
            "Test: Total time: 0:00:19 (0.4886 s / it)\n",
            "* Acc@1 53.020 Acc@5 95.490 loss 1.297\n",
            "Accuracy of the network on the 40 test images: 53.0%\n",
            "Epoch: [2]  [  0/625]  eta: 0:03:24  loss: 1.2744 (1.2744)  time: 0.3266  data: 0.1815  max mem: 3512\n",
            "Epoch: [2]  [100/625]  eta: 0:00:58  loss: 1.2344 (1.2343)  time: 0.1031  data: 0.0050  max mem: 3512\n",
            "Epoch: [2]  [200/625]  eta: 0:00:47  loss: 1.2207 (1.1949)  time: 0.1035  data: 0.0052  max mem: 3512\n",
            "Epoch: [2]  [300/625]  eta: 0:00:36  loss: 1.0318 (1.1699)  time: 0.1023  data: 0.0049  max mem: 3512\n",
            "Epoch: [2]  [400/625]  eta: 0:00:24  loss: 1.0624 (1.1428)  time: 0.1173  data: 0.0087  max mem: 3512\n",
            "Epoch: [2]  [500/625]  eta: 0:00:13  loss: 0.9473 (1.1158)  time: 0.1118  data: 0.0074  max mem: 3512\n",
            "Epoch: [2]  [600/625]  eta: 0:00:02  loss: 1.0271 (1.0932)  time: 0.1020  data: 0.0048  max mem: 3512\n",
            "Epoch: [2]  [624/625]  eta: 0:00:00  loss: 0.8587 (1.0869)  time: 0.1122  data: 0.0082  max mem: 3512\n",
            "Epoch: [2] Total time: 0:01:08 (0.1091 s / it)\n",
            "Averaged stats: loss: 0.8587 (1.0869)\n",
            "Epoch: [3]  [  0/625]  eta: 0:04:36  loss: 0.6215 (0.6215)  time: 0.4432  data: 0.2960  max mem: 3512\n",
            "Epoch: [3]  [100/625]  eta: 0:00:56  loss: 0.8739 (0.8464)  time: 0.1031  data: 0.0049  max mem: 3512\n",
            "Epoch: [3]  [200/625]  eta: 0:00:45  loss: 0.8147 (0.8583)  time: 0.1044  data: 0.0048  max mem: 3512\n",
            "Epoch: [3]  [300/625]  eta: 0:00:35  loss: 0.8349 (0.8602)  time: 0.1026  data: 0.0050  max mem: 3512\n",
            "Epoch: [3]  [400/625]  eta: 0:00:24  loss: 0.7767 (0.8412)  time: 0.1032  data: 0.0049  max mem: 3512\n",
            "Epoch: [3]  [500/625]  eta: 0:00:13  loss: 0.7718 (0.8306)  time: 0.1114  data: 0.0070  max mem: 3512\n",
            "Epoch: [3]  [600/625]  eta: 0:00:02  loss: 0.5718 (0.8221)  time: 0.1356  data: 0.0130  max mem: 3512\n",
            "Epoch: [3]  [624/625]  eta: 0:00:00  loss: 0.7838 (0.8205)  time: 0.1208  data: 0.0085  max mem: 3512\n",
            "Epoch: [3] Total time: 0:01:08 (0.1090 s / it)\n",
            "Averaged stats: loss: 0.7838 (0.8205)\n",
            "Test:  [ 0/40]  eta: 0:01:32  loss: 0.9084 (0.9084)  acc1: 66.0156 (66.0156)  acc5: 96.8750 (96.8750)  time: 2.3027  data: 1.9436  max mem: 3512\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.8075 (0.8292)  acc1: 70.7031 (70.4613)  acc5: 98.4375 (98.2701)  time: 0.4714  data: 0.1605  max mem: 3512\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.8009 (0.8187)  acc1: 70.7031 (70.3200)  acc5: 98.4375 (98.2200)  time: 0.4029  data: 0.1403  max mem: 3512\n",
            "Test: Total time: 0:00:19 (0.4846 s / it)\n",
            "* Acc@1 70.320 Acc@5 98.220 loss 0.819\n",
            "Accuracy of the network on the 40 test images: 70.3%\n",
            "Epoch: [4]  [  0/625]  eta: 0:03:08  loss: 0.6372 (0.6372)  time: 0.3018  data: 0.1862  max mem: 3512\n",
            "Epoch: [4]  [100/625]  eta: 0:00:57  loss: 0.6555 (0.6354)  time: 0.1038  data: 0.0050  max mem: 3512\n",
            "Epoch: [4]  [200/625]  eta: 0:00:46  loss: 0.6623 (0.6811)  time: 0.1040  data: 0.0049  max mem: 3512\n",
            "Epoch: [4]  [300/625]  eta: 0:00:35  loss: 0.6849 (0.6868)  time: 0.1230  data: 0.0102  max mem: 3512\n",
            "Epoch: [4]  [400/625]  eta: 0:00:24  loss: 0.7239 (0.6940)  time: 0.1064  data: 0.0061  max mem: 3512\n",
            "Epoch: [4]  [500/625]  eta: 0:00:13  loss: 0.7154 (0.6911)  time: 0.1037  data: 0.0051  max mem: 3512\n",
            "Epoch: [4]  [600/625]  eta: 0:00:02  loss: 0.6039 (0.6795)  time: 0.1022  data: 0.0048  max mem: 3512\n",
            "Epoch: [4]  [624/625]  eta: 0:00:00  loss: 0.7110 (0.6791)  time: 0.1008  data: 0.0047  max mem: 3512\n",
            "Epoch: [4] Total time: 0:01:07 (0.1073 s / it)\n",
            "Averaged stats: loss: 0.7110 (0.6791)\n",
            "Epoch: [5]  [  0/625]  eta: 0:03:02  loss: 0.6720 (0.6720)  time: 0.2927  data: 0.1668  max mem: 3512\n",
            "Epoch: [5]  [100/625]  eta: 0:00:57  loss: 0.4794 (0.5243)  time: 0.1020  data: 0.0051  max mem: 3512\n",
            "Epoch: [5]  [200/625]  eta: 0:00:46  loss: 0.5233 (0.5473)  time: 0.1054  data: 0.0057  max mem: 3512\n",
            "Epoch: [5]  [300/625]  eta: 0:00:35  loss: 0.5396 (0.5588)  time: 0.1035  data: 0.0048  max mem: 3512\n",
            "Epoch: [5]  [400/625]  eta: 0:00:24  loss: 0.5765 (0.5643)  time: 0.1188  data: 0.0085  max mem: 3512\n",
            "Epoch: [5]  [500/625]  eta: 0:00:13  loss: 0.5251 (0.5670)  time: 0.1083  data: 0.0064  max mem: 3512\n",
            "Epoch: [5]  [600/625]  eta: 0:00:02  loss: 0.6706 (0.5800)  time: 0.1028  data: 0.0048  max mem: 3512\n",
            "Epoch: [5]  [624/625]  eta: 0:00:00  loss: 0.4452 (0.5781)  time: 0.1075  data: 0.0060  max mem: 3512\n",
            "Epoch: [5] Total time: 0:01:07 (0.1084 s / it)\n",
            "Averaged stats: loss: 0.4452 (0.5781)\n",
            "Test:  [ 0/40]  eta: 0:02:12  loss: 0.7264 (0.7264)  acc1: 73.4375 (73.4375)  acc5: 98.0469 (98.0469)  time: 3.3242  data: 2.9800  max mem: 3512\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.7384 (0.7384)  acc1: 75.7812 (75.5022)  acc5: 98.4375 (98.3259)  time: 0.4216  data: 0.1382  max mem: 3512\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.7154 (0.7331)  acc1: 74.2188 (75.1600)  acc5: 98.8281 (98.5200)  time: 0.4370  data: 0.1603  max mem: 3512\n",
            "Test: Total time: 0:00:20 (0.5060 s / it)\n",
            "* Acc@1 75.160 Acc@5 98.520 loss 0.733\n",
            "Accuracy of the network on the 40 test images: 75.2%\n",
            "Test:  [ 0/40]  eta: 0:01:28  loss: 0.7264 (0.7264)  acc1: 73.4375 (73.4375)  acc5: 98.0469 (98.0469)  time: 2.2180  data: 1.8641  max mem: 3512\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.7384 (0.7384)  acc1: 75.7812 (75.5022)  acc5: 98.4375 (98.3259)  time: 0.5080  data: 0.2013  max mem: 3512\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.7154 (0.7331)  acc1: 74.2188 (75.1600)  acc5: 98.8281 (98.5200)  time: 0.3625  data: 0.1114  max mem: 3512\n",
            "Test: Total time: 0:00:19 (0.4831 s / it)\n",
            "* Acc@1 75.160 Acc@5 98.520 loss 0.733\n",
            "Accuracy of the network on the 40 test images: 75.2%\n"
          ]
        }
      ],
      "source": [
        "teacher = create_model(\n",
        "        'vit_base_patch16_224',\n",
        "        pretrained=True,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "teacher = teacher.to(device)\n",
        "teacher.load_state_dict(torch.load('./teacher.pth'))\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, teacher, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "# Train the student\n",
        "for p in teacher.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "MODEL_NAME = 'vit_tiny_patch16_224'\n",
        "\n",
        "model = create_model(\n",
        "        MODEL_NAME,\n",
        "        pretrained=True,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "\n",
        "print(f\"Start training for {EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_stats = train_one_epoch_distillation(\n",
        "        teacher, model, criterion, cifar10_training_loader,\n",
        "        optimizer, device, epoch, alpha=1.0, temp=1.0)\n",
        "    if epoch % 2 == 1:\n",
        "        test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "        print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}